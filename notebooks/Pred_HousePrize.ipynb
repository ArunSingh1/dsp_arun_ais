{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.read_csv('/home/arun/Documents/dsp_arun_ais/data/house-price/train.csv')\n",
    "df_test = pd.read_csv('/home/arun/Documents/dsp_arun_ais/data/house-price/test.csv')\n",
    "\n",
    "df_master = df_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import functions for preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export PYTHONPATH='/home/arun/Documents/dsp_arun_ais'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/arun/Documents/dsp_arun_ais/app')\n",
    "\n",
    "import preprocess\n",
    "from preprocess import fun_remove_object_cols, fillna, preproces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Basic Pipeline\n",
    "#### All non numeric columns are removed and Nan values are filled with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fun_remove_object_cols funciton removes the object cols in df\n",
    "\n",
    "dfbasic_train = fun_remove_object_cols(df_train)\n",
    "dfbasic_test =  fun_remove_object_cols(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna func fills nans with 0\n",
    "\n",
    "dfbasic_train = fillna(dfbasic_train)\n",
    "dfbasic_test = fillna(dfbasic_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training for Basic pipelinefrom sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.linear_model import Lasso\n",
    "# from sklearn.tree import DecisionTreeRegressors\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "linreg = LinearRegression()\n",
    "l2 = Ridge(alpha=1.0, normalize=True)\n",
    "l1 = Lasso(alpha=1.0, normalize=True)\n",
    "decision = DecisionTreeRegressor(random_state=0)\n",
    "regressor = RandomForestRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code working\n"
     ]
    }
   ],
   "source": [
    "from train import training_data_prep, model_train, initialise_models, model_evalution, compute_rmsle, saving_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = training_data_prep(dfbasic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n",
      "Log Root Mean Squared Error 0.201\n",
      "/home/arun/Documents/dsp_arun_ais/models/basicpipeline/LinearRegression().plk\n",
      "Lasso(normalize=True)\n",
      "Log Root Mean Squared Error 0.201\n",
      "/home/arun/Documents/dsp_arun_ais/models/basicpipeline/Lasso(normalize=True).plk\n",
      "Ridge(normalize=True)\n",
      "Log Root Mean Squared Error 0.158\n",
      "/home/arun/Documents/dsp_arun_ais/models/basicpipeline/Ridge(normalize=True).plk\n",
      "DecisionTreeRegressor(random_state=0)\n",
      "Log Root Mean Squared Error 0.198\n",
      "/home/arun/Documents/dsp_arun_ais/models/basicpipeline/DecisionTreeRegressor(random_state=0).plk\n",
      "RandomForestRegressor(random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arun/Documents/dsp_arun_ais/myenvdsp/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3355174784.13208, tolerance: 772707392.4121249\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Root Mean Squared Error 0.15\n",
      "/home/arun/Documents/dsp_arun_ais/models/basicpipeline/RandomForestRegressor(random_state=0).plk\n"
     ]
    }
   ],
   "source": [
    "#initialise_models()\n",
    "\n",
    "###PIPELINE\n",
    "#Step 1 list of Classifiers are initilased and looped through \n",
    "\n",
    "#Step2 for every Classifer Model Training is performed using Func \"model_train\"\n",
    "\n",
    "#Step3 Every model is Evalated against their y_actual ans LRMSE is calculated  using Func \"model_evalution\" & \"compute_rmsle\"\n",
    "\n",
    "#Step4 ALL models are saved using joblib in folder models/basicpipeline with respective names using Func \"saving_models\"\n",
    "\n",
    "classifiers= [ linreg, l1, l2, decision, regressor]\n",
    "for i in classifiers:\n",
    "    print(i)\n",
    "    y_pred = model_train(i, X_train, y_train, X_test)  \n",
    "    model_evalution(y_test, y_pred, i)\n",
    "    saving_models(i)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not a Basic approarch,\n",
    "#### Different Preprocessing methods are done,\n",
    "#### droping negatively correalted colns with target variablt\n",
    "#### Encoding the obj cols, imputation of Nulls are carried out\n",
    "#### functions are imported from preprocess.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 80)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maintrain = preproces(df_train) #imported from preprocess.py\n",
    "df_maintest = preproces(df_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 67)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_maintrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = training_data_prep(df_maintrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code working\n",
      "Lasso(normalize=True)\n",
      "Log Root Mean Squared Error 0.981\n",
      "/home/arun/Documents/dsp_arun_ais/models/mainpipeline/Lasso(normalize=True).plk\n",
      "Ridge(normalize=True)\n",
      "Log Root Mean Squared Error 0.923\n",
      "/home/arun/Documents/dsp_arun_ais/models/mainpipeline/Ridge(normalize=True).plk\n",
      "DecisionTreeRegressor(random_state=0)\n",
      "Log Root Mean Squared Error 1.028\n",
      "/home/arun/Documents/dsp_arun_ais/models/mainpipeline/DecisionTreeRegressor(random_state=0).plk\n",
      "RandomForestRegressor(random_state=0)\n",
      "Log Root Mean Squared Error 0.827\n",
      "/home/arun/Documents/dsp_arun_ais/models/mainpipeline/RandomForestRegressor(random_state=0).plk\n"
     ]
    }
   ],
   "source": [
    "#initialise_models()\n",
    "\n",
    "###PIPELINE\n",
    "#Step 1 list of Classifiers are initilased and looped through \n",
    "\n",
    "#Step2 for every Classifer Model Training is performed using Func \"model_train\"\n",
    "\n",
    "#Step3 Every model is Evalated against their y_actual ans LRMSE is calculated  using Func \"model_evalution\" & \"compute_rmsle\"\n",
    "\n",
    "#Step4 ALL models are saved using joblib in folder models/basicpipeline with respective names using Func \"saving_models\"\n",
    "\n",
    "classifiers= [ l1, l2, decision, regressor]\n",
    "for i in classifiers:\n",
    "    print(i)\n",
    "    y_pred = model_train(i, X_train, y_train, X_test)  \n",
    "    model_evalution(y_test, y_pred, i)\n",
    "    saving_models(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LRMSE has increased compared to basic modelpipeline and the models are saved in folder /models/mainpipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lets load desicion tree model and do inference on test data (ie creating submission.csv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = joblib.load(\"/home/arun/Documents/dsp_arun_ais/models/mainpipeline/DecisionTreeRegressor(random_state=0).plk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import submission_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_to_csv(final_model, df_maintrain)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
